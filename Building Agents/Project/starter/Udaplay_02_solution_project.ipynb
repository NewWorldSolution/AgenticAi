{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from tavily import TavilyClient\n",
    "from datetime import datetime\n",
    "from lib.vector_db import VectorStoreManager, CorpusLoaderService\n",
    "from lib.rag import RAG\n",
    "from pydantic import BaseModel, Field\n",
    "from lib.parsers import PydanticOutputParser\n",
    "from typing import TypedDict, Optional, List, Dict, Any, Union\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.vector_db import VectorStoreManager\n",
    "from lib.memory import LongTermMemory, MemoryFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "        args:\n",
    "        - query: a question about game industry. \n",
    "\n",
    "        You'll receive results as list. Each element contains:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts = [query],\n",
    "        n_results=5,\n",
    "        include=[\"metadatas\", \"distances\"]\n",
    "    )\n",
    "    games = []\n",
    "    metas = results[\"metadatas\"][0]\n",
    "    dists = results[\"distances\"][0]\n",
    "    for meta, dist in zip(metas, dists):\n",
    "        games.append({\n",
    "            \"Platform\": meta.get(\"Platform\"),\n",
    "            \"Name\": meta.get(\"Name\"),\n",
    "            \"YearOfRelease\": meta.get(\"YearOfRelease\"),\n",
    "            \"Description\": meta.get(\"Description\"),\n",
    "            \"distance\": float(dist),\n",
    "        })\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ac03172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10038e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO QUERY: first 3D platformer Mario game\n",
      "1. Super Mario 64 (1996) [Nintendo 64]  distance=0.1032\n",
      "2. Super Mario World (1990) [Super Nintendo Entertainment System (SNES)]  distance=0.1278\n",
      "3. Mario Kart 8 Deluxe (2017) [Nintendo Switch]  distance=0.1880\n",
      "4. Super Smash Bros. Melee (2001) [GameCube]  distance=0.1920\n",
      "5. Pokémon Gold and Silver (1999) [Game Boy Color]  distance=0.2042\n"
     ]
    }
   ],
   "source": [
    "demo_q = \"first 3D platformer Mario game\"\n",
    "demo_results = retrieve_game(demo_q)\n",
    "\n",
    "print(\"DEMO QUERY:\", demo_q)\n",
    "for i, r in enumerate(demo_results, 1):\n",
    "    print(f\"{i}. {r['Name']} ({r['YearOfRelease']}) [{r['Platform']}]  distance={r['distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool\n",
    "    description: str\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "        args: \n",
    "        - question: original question from user\n",
    "        - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "        The result includes:\n",
    "        - useful: whether the documents are useful to answer the question\n",
    "        - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "    docs_text = \"\\n\\n\".join(\n",
    "        f\"Doc {i+1}:\\n\"\n",
    "        f\"Name: {d.get('Name')}\\n\"\n",
    "        f\"Platform: {d.get('Platform')}\\n\"\n",
    "        f\"YearOfRelease: {d.get('YearOfRelease')}\\n\"\n",
    "        f\"Description: {d.get('Description')}\"\n",
    "        for i, d in enumerate(retrieved_docs or [])\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a strict evaluator for a RAG system.\n",
    "\n",
    "    Task:\n",
    "    Decide if the retrieved documents contain enough specific information to answer the question.\n",
    "\n",
    "    Question: \n",
    "    \n",
    "    {question}\n",
    "    \n",
    "    Retrieved Documents: \n",
    "    {docs_text}\n",
    "    \n",
    "    Return ONLY valid JSON in this schema:\n",
    "    {{\n",
    "    \"useful\": true/false,\n",
    "    \"description\": \"Explain what key info is present/missing and end with ACCEPT or REJECT\"\n",
    "    }}\n",
    "\n",
    "    Rules:\n",
    "    - useful=true ONLY if the docs directly contain the answer (not just vaguely related).\n",
    "    - useful=false if missing dates/platform/version details or if the docs are irrelevant.\n",
    "    \"\"\"\n",
    "    \n",
    "    judge = LLM(model=\"gpt-4o-mini\", temperature=0)\n",
    "    ai_message = judge.invoke(prompt)\n",
    "    parser = PydanticOutputParser(model_class=EvaluationReport)\n",
    "    report = parser.parse(ai_message)\n",
    "    return report.model_dump() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "\n",
    "@tool\n",
    "def game_web_search(question: str, search_depth: str = \"advanced\") -> Dict:\n",
    "    \"\"\"\n",
    "    Web search: Uses Tavily to search the web for game industry information\n",
    "    when internal vector database results are insufficient.\n",
    "        args:\n",
    "        - question: a question about game industry.\n",
    "        - search_depth (str): The depth of the search, either 'basic' or 'advanced (default)'. \n",
    "    \"\"\"\n",
    "    tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    search_results = tavily_client.search(\n",
    "        question, \n",
    "        search_depth=search_depth,  \n",
    "        include_answer=True, \n",
    "        include_raw_results=False, \n",
    "        include_images=False)\n",
    "    formatted_results = {\n",
    "        \"answer\": search_results.get(\"answer\", \"\"),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"title\": r.get(\"title\"),\n",
    "                \"url\": r.get(\"url\"),\n",
    "                \"content\": r.get(\"content\"),\n",
    "            }\n",
    "            for r in (search_results.get(\"results\") or [])\n",
    "        ],\n",
    "        \"search_metadata\": {\n",
    "            \"query\": question,\n",
    "            \"search_depth\": search_depth,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda08dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Long Term Memory Adapter\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "db_manager = VectorStoreManager(openai_api_key=OPENAI_API_KEY)\n",
    "ltm = LongTermMemory(db_manager)\n",
    "\n",
    "class MemoryAdapter:\n",
    "    \"\"\"\n",
    "    Adapter so your agent can do:\n",
    "      - memory.search(question) -> returns a string or None\n",
    "      - memory.store(question, answer)\n",
    "    while internally using LongTermMemory's API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ltm:LongTermMemory, owner: str = \"default_agent\", namespace: str = \"udaplay\"):\n",
    "\n",
    "        self.ltm = ltm\n",
    "        self.owner = owner\n",
    "        self.namespace = namespace\n",
    "    \n",
    "    def search(self, query: str = None, query_text: str = None, question: str = None, limit: int = 1):\n",
    "        text = query_text or query or question\n",
    "        if not text:\n",
    "            return None\n",
    "\n",
    "        results = self.ltm.search(\n",
    "            query_text=text,\n",
    "            owner=self.owner,\n",
    "            limit=limit,\n",
    "            namespace=self.namespace\n",
    "        )\n",
    "        if results.fragments:\n",
    "            return results.fragments[0].content\n",
    "        return None\n",
    "    \n",
    "    def store(self, question: str, answer: str):\n",
    "        content = f\"Q: {question}\\nA: {answer}\"\n",
    "        self.ltm.register(MemoryFragment(content=content, owner=self.owner, namespace=self.namespace))\n",
    "\n",
    "memory = MemoryAdapter(ltm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "from pdb import run\n",
    "\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    question: str\n",
    "    history: List[Dict[str, str]]\n",
    "    retrieved_docs: List[Dict[str, Any]]\n",
    "    evaluation: Dict[str, Any] #{useful: bool, description: str}\n",
    "    web: Dict[str, Any] #Tavily respond\n",
    "    final_context: str\n",
    "    answer: str\n",
    "    memory_hit: Optional[str]\n",
    "    used_memory: bool\n",
    "\n",
    "\n",
    "\n",
    "class ResearchAgent:\n",
    "    def __init__(self, llm: LLM,memory):\n",
    "        self.llm = llm\n",
    "        self.workflow = self._create_state_machine()\n",
    "        self.memory = memory\n",
    "        self.history = []\n",
    "\n",
    "    def _retrieve(self, state:AgentState) -> AgentState:\n",
    "        \"\"\"Retrieve relevant documents from the vector database \"\"\"\n",
    "        docs = retrieve_game(state[\"question\"])\n",
    "        return {\"retrieved_docs\": docs}\n",
    "    \n",
    "    def _evaluate(self, state:AgentState) -> AgentState:\n",
    "        \"\"\"Evaluate the usefulness of the retrieved documents \"\"\"\n",
    "        report= evaluate_retrieval(state[\"question\"], state[\"retrieved_docs\"])\n",
    "        return {\"evaluation\": report}\n",
    "    \n",
    "    def _memory_check(self, state:AgentState) -> AgentState:\n",
    "        \"\"\"Check memory for relevant past interactions \"\"\"\n",
    "        hit= self.memory.search(state[\"question\"])\n",
    "        if hit:\n",
    "            return {\n",
    "                \"memory_hit\": hit,\n",
    "                \"used_memory\": True\n",
    "            }\n",
    "        return {\"used_memory\": False}\n",
    "    \n",
    "    def _web_search(self, state:AgentState) -> AgentState:\n",
    "        web_info = game_web_search(state[\"question\"])\n",
    "        return {\"web\": web_info}\n",
    "    \n",
    "    \n",
    "    def _build_context(self, state:AgentState) -> AgentState:\n",
    "        # 1) Check if memory hit exists, use it as context\n",
    "        if state.get(\"used_memory\") and state.get(\"memory_hit\"):\n",
    "            return {\"final_context\": state[\"memory_hit\"]}\n",
    "        \n",
    "        # 2) If retrieved docs are useful, use DB docs as context\n",
    "\n",
    "        if state.get(\"evaluation\", {}).get(\"useful\"):\n",
    "            context = \"\\n\\n\".join(\n",
    "                f\"{d.get('Name')} ({d.get('YearOfRelease')}) [{d.get('Platform')}]: {d.get('Description')}\"\n",
    "                for d in state.get(\"retrieved_docs\", [])\n",
    "            )\n",
    "            return {\"final_context\": context}\n",
    "        \n",
    "        # 3) Otherwise, use web search results as context\n",
    "        parts = [state.get(\"web\", {}).get(\"answer\", \"\")]\n",
    "        for r in state.get(\"web\", {}).get(\"results\", [])[:3]:\n",
    "            parts.append(\n",
    "                f\"Title: {r.get('title')}\\n\"\n",
    "                f\"URL: {r.get('url')}\\n\"\n",
    "                f\"Snippet: {r.get('content', '')}\"\n",
    "            )\n",
    "        return {\"final_context\": \"\\n\\n\".join(parts)}\n",
    "    \n",
    "    def _answer(self, state:AgentState) -> AgentState:\n",
    "\n",
    "        history_text = \"\"\n",
    "        for turn in state.get(\"history\", [])[-6:]:  # last 3 exchanges\n",
    "            history_text += f\"{turn['role'].upper()}: {turn['content']}\\n\"\n",
    "        message = [\n",
    "            SystemMessage(content=(\n",
    "                \"You are a game industry research assistant. \"\n",
    "                \"Use the conversation history ONLY if it helps resolve references. \"\n",
    "                \"Answer using ONLY the provided context for factual claims. \"\n",
    "                \"If URLs are present in the context, cite them as (Source: <url>).\"\n",
    "            )),\n",
    "           UserMessage(content=(\n",
    "                f\"Conversation history:\\n{history_text}\\n\"\n",
    "                f\"Question: {state['question']}\\n\\n\"\n",
    "                f\"Context:\\n{state.get('final_context','')}\\n\\nAnswer:\"\n",
    "            ))\n",
    "        ]\n",
    "        ai = self.llm.invoke(message)\n",
    "        return {\"answer\": ai.content}\n",
    "    \n",
    "    def _store_memory(self, state:AgentState) -> AgentState:\n",
    "         # store ONLY when we used web fallback (simple rule)\n",
    "        if state.get(\"web\") and state.get(\"answer\"):\n",
    "            self.memory.store(question=state[\"question\"], answer=state[\"answer\"])\n",
    "        return {}\n",
    "    \n",
    "    def _create_state_machine(self) -> StateMachine[AgentState]:\n",
    "        \"\"\"Create the internal state machine for the agent\"\"\"\n",
    "        machine = StateMachine[AgentState](AgentState)\n",
    "        \n",
    "        #Steps\n",
    "        entry = EntryPoint[AgentState]()\n",
    "        retrieve = Step[AgentState](\"retrieve\", self._retrieve)\n",
    "        evaluate = Step[AgentState](\"evaluate\", self._evaluate)\n",
    "        web_search = Step[AgentState](\"web_search\", self._web_search)\n",
    "        memory_check = Step[AgentState](\"memory_check\", self._memory_check)\n",
    "        context = Step[AgentState](\"context\", self._build_context)\n",
    "        answer = Step[AgentState](\"answer\", self._answer)\n",
    "        store_memory = Step[AgentState](\"store_memory\", self._store_memory)\n",
    "        termination = Termination[AgentState]()\n",
    "\n",
    "        machine.add_steps([\n",
    "            entry,\n",
    "            retrieve,\n",
    "            evaluate,\n",
    "            web_search,\n",
    "            memory_check,\n",
    "            context,\n",
    "            answer,\n",
    "            store_memory,\n",
    "            termination,\n",
    "            \n",
    "        ])\n",
    "        #Transitions\n",
    "\n",
    "        machine.connect(entry, retrieve)\n",
    "        machine.connect(retrieve, evaluate)\n",
    "\n",
    "        def route_after_eval(state: AgentState) -> Union[Step[AgentState], str]: \n",
    "            \"\"\"After evaluate: if useful -> context else -> memory_check\"\"\"\n",
    "            if state.get(\"evaluation\", {}).get(\"useful\"):\n",
    "                return context\n",
    "            return memory_check\n",
    "        machine.connect(evaluate,[memory_check, context], route_after_eval)\n",
    "\n",
    "        def route_after_memory(state: AgentState) -> Union[Step[AgentState], str]: \n",
    "            \"\"\"After memory check: if used_memory -> context else -> web_search\"\"\"\n",
    "            if state.get(\"used_memory\"):\n",
    "                return context\n",
    "            return web_search\n",
    "        \n",
    "        machine.connect(memory_check, [context, web_search], route_after_memory)\n",
    "        machine.connect(web_search, context)\n",
    "        machine.connect(context, answer)\n",
    "\n",
    "        def route_after_answer(state: AgentState) -> Union[Step[AgentState], str]: \n",
    "            \"\"\"After answer: if web used -> store_memory else -> termination\"\"\"\n",
    "            if state.get(\"web\"):\n",
    "                return store_memory\n",
    "            return termination\n",
    "        machine.connect(answer, [store_memory, termination], route_after_answer)\n",
    "        machine.connect(store_memory, termination)\n",
    "\n",
    "        return machine\n",
    "    \n",
    "    def invoke(self, question: str):\n",
    "        initial_state: AgentState = {\"question\": question, \"history\": self.history}\n",
    "        run_object = self.workflow.run(initial_state)\n",
    "        final_state=  run_object.get_final_state()\n",
    "\n",
    "        if final_state and final_state.get(\"answer\"):\n",
    "            self.history.append({\"role\": \"user\", \"content\": question})\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": final_state[\"answer\"]})\n",
    "        return run_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: context\n",
      "[StateMachine] Executing step: answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Question: When Pokémon Gold and Silver was released?\n",
      "Answer: Pokémon Gold and Silver was released in 1999.\n",
      "--------------------------------------------------\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: context\n",
      "[StateMachine] Executing step: answer\n",
      "[StateMachine] Terminating: __termination__\n",
      "Question: Which one was the first 3D platformer Mario game?\n",
      "Answer: The first 3D platformer Mario game is Super Mario 64, released in 1996.\n",
      "--------------------------------------------------\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: memory_check\n",
      "[StateMachine] Executing step: web_search\n",
      "[StateMachine] Executing step: context\n",
      "[StateMachine] Executing step: answer\n",
      "[StateMachine] Executing step: store_memory\n",
      "[StateMachine] Terminating: __termination__\n",
      "Question: Was Mortal Kombat X realeased for Playstation 5?\n",
      "Answer: Mortal Kombat X was originally released for PlayStation 4, but it is playable on PlayStation 5 with some features missing (Source: <https://store.playstation.com/en-us/product/UP1018-CUSA00967_00-MORTALKOMBATX000>).\n",
      "--------------------------------------------------\n",
      "\n",
      "useful: False\n",
      "used_web: True\n"
     ]
    }
   ],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "\n",
    "research_agent = ResearchAgent(llm=LLM(model=\"gpt-4o-mini\", temperature=0), memory=memory)\n",
    "questions = [\n",
    "    \"When Pokémon Gold and Silver was released?\",\n",
    "    \"Which one was the first 3D platformer Mario game?\",\n",
    "    \"Was Mortal Kombat X realeased for Playstation 5?\"\n",
    "]\n",
    "for q in questions:\n",
    "    run = research_agent.invoke(q)\n",
    "    final_state = run.get_final_state()\n",
    "    print(f\"Question: {q}\\nAnswer: {final_state.get('answer')}\\n{'-'*50}\\n\")   \n",
    "\n",
    "#For debugging purposes, you can check the final state\n",
    "# to see which paths were taken\n",
    "\n",
    "    #print(\"useful:\", final_state.get(\"evaluation\", {}).get(\"useful\"))\n",
    "    #print(\"used_web:\", \"web\" in final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes\n",
    "\n",
    "# I implement everything above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (agent)",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
