{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baf30a2",
   "metadata": {},
   "source": [
    "# [STARTER] Exercise - Building a Multi-Step State Machine Agent\n",
    "\n",
    "In this exercise, you will build an agent that manages a multi-step workflow using a state machine. You’ll define a custom state schema, implement step logic, connect steps (including conditional routing and loops), and run the workflow to process user input through several transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9056",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You have learned how to use a state machine to manage workflow steps and transitions. Now, your challenge is to:\n",
    "\n",
    "- Define a state schema with multiple fields (e.g., user_query, instructions, messages, current_tool_calls).\n",
    "- Implement at least three step functions:\n",
    "    - Prepare Messages: Assemble the conversation history and any required context for the LLM.\n",
    "    - LLM: Call the language model to generate a response or tool call.\n",
    "    - Tools: Execute any required tool calls and update the state with results.\n",
    "- Connect steps to form a workflow, including:\n",
    "    - Entrypoint and Termination steps to start and end the workflow.\n",
    "    - Conditional routing: If the LLM response includes tool calls, route to the Tools step; otherwise, proceed to Termination.\n",
    "    - Looping: After executing tools, return to the LLM step to continue the workflow until there are no more tool calls.\n",
    "- Run your state machine with a sample input and inspect the state transitions and snapshots to understand how your agent processes a task step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0e231",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42ccb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Union\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n",
    "from lib.llm import LLM\n",
    "from lib.messages import AIMessage, UserMessage, SystemMessage, ToolMessage\n",
    "from lib.tooling import Tool, ToolCall, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8686cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41de723",
   "metadata": {},
   "source": [
    "## Define a State Schema\n",
    "\n",
    "Create a TypedDict to represent the agent’s state, including fields for the user query, instructions, message history, and any pending tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99605c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the AgentState TypedDict\n",
    "# Include fields for user_query, instructions, messages, and current_tool_calls\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Schema for agent state definition.\n",
    "    Attributes:\n",
    "       user_query (str): The original query from the user.\n",
    "       instructions (str): Instructions for the agent.\n",
    "       messages: A list of messages exchanged in the conversation.\n",
    "       current_tool_calls: A list of tool calls made by the agent.\n",
    "    \"\"\" \n",
    "    user_query: str\n",
    "    instructions: str\n",
    "    messages: List[dict]\n",
    "    current_tool_calls: Optional[List[ToolCall]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da75109",
   "metadata": {},
   "source": [
    "## Define the Tools you will use\n",
    "\n",
    "Feel free to modify to add any tool you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d171e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_games(num_games:int=1, top:bool=True) -> str:\n",
    "    \"\"\"\n",
    "    Returns the top or bottom N games with highest or lowest scores.    \n",
    "    args:\n",
    "        num_games (int): Number of games to return (default is 1)\n",
    "        top (bool): If True, return top games, otherwise return bottom (default is True)\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        {\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98},\n",
    "        {\"Game\": \"Super Mario Odyssey\", \"Platform\": \"Switch\", \"Score\": 97},\n",
    "        {\"Game\": \"Metroid Prime\", \"Platform\": \"GameCube\", \"Score\": 97},\n",
    "        {\"Game\": \"Super Smash Bros. Brawl\", \"Platform\": \"Wii\", \"Score\": 93},\n",
    "        {\"Game\": \"Mario Kart 8 Deluxe\", \"Platform\": \"Switch\", \"Score\": 92},\n",
    "        {\"Game\": \"Fire Emblem: Awakening\", \"Platform\": \"3DS\", \"Score\": 92},\n",
    "        {\"Game\": \"Donkey Kong Country Returns\", \"Platform\": \"Wii\", \"Score\": 87},\n",
    "        {\"Game\": \"Luigi's Mansion 3\", \"Platform\": \"Switch\", \"Score\": 86},\n",
    "        {\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85},\n",
    "        {\"Game\": \"Animal Crossing: New Leaf\", \"Platform\": \"3DS\", \"Score\": 88}\n",
    "    ]\n",
    "    # Sort the games list by Score\n",
    "    # If top is True, descending order\n",
    "    sorted_games = sorted(data, key=lambda x: x['Score'], reverse=top)\n",
    "    \n",
    "    # Return the N games\n",
    "    return sorted_games[:num_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07c2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add as many tools as you want\n",
    "# Use the @tool decorator and implement functions like get_games\n",
    "\n",
    "tools = [get_games]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052be6c2",
   "metadata": {},
   "source": [
    "## Create the Steps\n",
    "\n",
    "Write functions for each step in your workflow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd86828",
   "metadata": {},
   "source": [
    "**Prepare Messages**: Build the message list for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6341e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the prepare_messages_step function\n",
    "# This function should take AgentState and return AgentState with prepared messages\n",
    "# Use instructions to create the SystemMessage and user_query to create UserMessage\n",
    "# Then return AgentState with the messages list with the SystemMessage and UserMessage\n",
    "\n",
    "def prepare_messages_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Step logic: Prepare message for LLM consumption.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=state['instructions']),\n",
    "        UserMessage(content=state['user_query'])\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages  \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ce1ea",
   "metadata": {},
   "source": [
    "**LLM Step**: Call the language model and check for tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dbf3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the llm_step function\n",
    "# This function should process the state through an LLM and handle tool calls\n",
    "# It should append the AIMessage to the messages list \n",
    "# and return the State with the messages and the current_tool_calls.\n",
    "# You can get the tool_calls object accessing it from the llm invoke response: `response.tool_calls`\n",
    "\n",
    "def llm_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Step logic: Process state through LLM and handle tool calls.\"\"\"\n",
    "    llm = LLM(\n",
    "        model =\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        tools=tools    \n",
    "    )\n",
    "    response = llm.invoke(state['messages'])\n",
    "    tool_calls = response.tool_calls if response.tool_calls else None\n",
    "\n",
    "    ai_message = AIMessage(content=response.content, tool_calls=tool_calls)\n",
    "    updated_messages = state['messages'] + [ai_message]\n",
    "\n",
    "    return {\n",
    "        \"messages\": updated_messages,\n",
    "        \"current_tool_calls\": tool_calls\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288ecd4",
   "metadata": {},
   "source": [
    "**Tool Step**: Execute any tool calls and update the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32124e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the tool_step function\n",
    "# This function should execute any pending tool calls and update the state\n",
    "# Make sure to iterate over tool_calls object\n",
    "# Extend the messages list from the state with all ToolMessages\n",
    "# Don't forget to set current_tool_calls to None\n",
    "\n",
    "def tool_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Step logic: Execute pending tool calls and update state.\"\"\"\n",
    "    tool_calls = state['current_tool_calls'] or []\n",
    "    tool_messages = []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        function_name = call.function.name\n",
    "        function_args = json.loads(call.function.arguments)\n",
    "        tool_call_id = call.id\n",
    "        tool = next((t for t in tools if t.name == function_name), None)\n",
    "        if tool:\n",
    "            result = tool(**function_args)\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content = json.dumps(result), \n",
    "                    tool_call_id=tool_call_id, \n",
    "                    name = function_name\n",
    "                )\n",
    "            )\n",
    "    return {\n",
    "        'messages': state['messages'] + tool_messages,\n",
    "        'current_tool_calls': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aaddee",
   "metadata": {},
   "source": [
    "## Build and Connect the State Machine\n",
    "\n",
    "Add your steps to the state machine, and connect them with transitions. Use conditional routing to decide whether to call tools or terminate, and loop as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ca0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize the StateMachine with the AgentState\n",
    "workflow = StateMachine[AgentState](AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52f8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = EntryPoint[AgentState]()\n",
    "message_prep = Step[AgentState](\"message_prep\", prepare_messages_step)\n",
    "llm_processor = Step[AgentState](\"llm_processor\", llm_step)\n",
    "tool_executor = Step[AgentState](\"tool_executor\", tool_step)\n",
    "termination = Termination[AgentState]()\n",
    "\n",
    "# TODO: Add all the steps to the workflow using workflow.add_steps   \n",
    "workflow.add_steps([\n",
    "    entry,\n",
    "    message_prep,\n",
    "    llm_processor,\n",
    "    tool_executor,\n",
    "    termination\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae5a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, message_prep)\n",
    "workflow.connect(message_prep, llm_processor)\n",
    "\n",
    "# Transition based on whether there are tool calls\n",
    "def check_tool_calls(state: AgentState) -> Union[Step[AgentState], str]:\n",
    "    \"\"\"Transition logic: Check if there are tool calls\"\"\"\n",
    "    if state.get(\"current_tool_calls\"):\n",
    "        return tool_executor\n",
    "    return termination\n",
    "\n",
    "# Routing: If tool calls -> tool_executor\n",
    "workflow.connect(\n",
    "    source=llm_processor, \n",
    "    targets=[tool_executor, termination], \n",
    "    condition=check_tool_calls\n",
    ")\n",
    "\n",
    "# Looping: Go back to llm after tool execution\n",
    "workflow.connect(\n",
    "    source=tool_executor, \n",
    "    targets=llm_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeb8b6",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4facbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: AgentState = {\n",
    "    \"user_query\": \"What's the best game in the dataset?\",\n",
    "    \"instructions\": \"You can bring insights about a game dataset based on users questions\",\n",
    "    \"messages\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8174c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "key prefix: voc-3423\n",
      "base_url: https://openai.vocareum.com/v1\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "key prefix: voc-3423\n",
      "base_url: https://openai.vocareum.com/v1\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f2c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(role='system', content='You can bring insights about a game dataset based on users questions'),\n",
       " UserMessage(role='user', content=\"What's the best game in the dataset?\"),\n",
       " AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_mFKoTsg7lU083iIB6naOOQlb', function=Function(arguments='{\"num_games\":1,\"top\":true}', name='get_games'), type='function')]),\n",
       " ToolMessage(role='tool', content='[{\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98}]', tool_call_id='call_mFKoTsg7lU083iIB6naOOQlb', name='get_games'),\n",
       " AIMessage(role='assistant', content='The best game in the dataset is **The Legend of Zelda: Breath of the Wild** for the **Switch**, with a score of **98**.', tool_calls=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57846326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create more test cases\n",
    "# Initialize the state and run the workflow with another sample query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89629e4a",
   "metadata": {},
   "source": [
    "## Optional \n",
    "\n",
    "Create an Agent class to encapsulate State Machine logic. Then try adding more tools, and experiment with different user queries to see how the workflow adapts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e7d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your Agent\n",
    "# Develope the following methods: _prepare_messages_step, _llm_step, _tool_step, _create_state_machine\n",
    "from platform import machine\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, \n",
    "                 model_name: str,\n",
    "                 instructions: str, \n",
    "                 tools: List[Tool] = None,\n",
    "                 temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize an Agent instance\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name/identifier of the LLM model to use\n",
    "            instructions: System instructions for the agent\n",
    "            tools: Optional list of tools available to the agent\n",
    "            temperature: Temperature parameter for LLM (default: 0.7)\n",
    "        \"\"\"\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools if tools else []\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "                \n",
    "        # Initialize state machine\n",
    "        self.workflow = self._create_state_machine()\n",
    "\n",
    "    def _prepare_messages_step(self, state: AgentState) -> AgentState:\n",
    "        message =[\n",
    "            SystemMessage(content=state['instructions']),\n",
    "            UserMessage(content=state['user_query'])\n",
    "        ]\n",
    "        return {\n",
    "            \"messages\": message\n",
    "        }\n",
    "\n",
    "    def _llm_step(self, state: AgentState) -> AgentState:\n",
    "        llm = LLM(\n",
    "            model= self.model_name,\n",
    "            temperature= self.temperature,\n",
    "            tools= self.tools\n",
    "        )\n",
    "        response = llm.invoke(state[\"messages\"])\n",
    "        tool_calls = response.tool_calls if response.tool_calls else None\n",
    "\n",
    "        ai_message = AIMessage(content=response.content, tool_calls=tool_calls)\n",
    "        return{\n",
    "            \"messages\": state[\"messages\"] + [ai_message],\n",
    "            \"current_tool_calls\": tool_calls\n",
    "        }\n",
    "\n",
    "    def _tool_step(self, state: AgentState) -> AgentState:\n",
    "        tool_calls = state['current_tool_calls'] or []\n",
    "        tool_messages = []\n",
    "\n",
    "        for call in tool_calls:\n",
    "            function_name = call.function.name\n",
    "            function_args = json.loads(call.function.arguments)\n",
    "            tool_call_id = call.id\n",
    "            tool = next((t for t in self.tools if t.name == function_name), None)\n",
    "            if tool:\n",
    "                result = tool(**function_args)\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content = json.dumps(result), \n",
    "                        tool_call_id=tool_call_id, \n",
    "                        name = function_name\n",
    "                    )\n",
    "                )\n",
    "        return {\n",
    "            'messages': state['messages'] + tool_messages,\n",
    "            'current_tool_calls': None\n",
    "        }\n",
    "\n",
    "    def _create_state_machine(self) -> StateMachine[AgentState]:\n",
    "        machine = StateMachine[AgentState](AgentState)\n",
    "       \n",
    "        entry = EntryPoint[AgentState]()\n",
    "        message_prep = Step[AgentState](\"message_prep\", self._prepare_messages_step)\n",
    "        llm_processor = Step[AgentState](\"llm_processor\", self._llm_step)\n",
    "        tool_processor = Step[AgentState](\"tool_processor\", self._tool_step)\n",
    "        termination = Termination[AgentState]()\n",
    "\n",
    "        machine.add_steps([\n",
    "            entry,\n",
    "            message_prep,\n",
    "            llm_processor,\n",
    "            tool_processor,\n",
    "            termination\n",
    "        ])\n",
    "\n",
    "        machine.connect(entry, message_prep)\n",
    "        machine.connect(message_prep, llm_processor)\n",
    "\n",
    "        def _check_tool_calls(self, state: AgentState) -> Union[Step[AgentState], str]:\n",
    "            \"\"\"Transition logic: Check if there are tool calls\"\"\"\n",
    "            if state.get(\"current_tool_calls\"):\n",
    "                return tool_processor\n",
    "            return termination\n",
    "\n",
    "        machine.connect(llm_processor, [tool_processor, termination], condition=self._check_tool_calls)\n",
    "        machine.connect(tool_processor, llm_processor)\n",
    "\n",
    "        return machine\n",
    "        \n",
    "\n",
    "    def invoke(self, query: str) -> Run:\n",
    "        \"\"\"\n",
    "        Run the agent on a query\n",
    "        \n",
    "        Args:\n",
    "            query: The user's query to process\n",
    "            \n",
    "        Returns:\n",
    "            The final run object after processing\n",
    "        \"\"\"\n",
    "\n",
    "        initial_state: AgentState = {\n",
    "            \"user_query\": query,\n",
    "            \"instructions\": self.instructions,\n",
    "            \"messages\": [],\n",
    "        }\n",
    "\n",
    "        run_object = self.workflow.run(initial_state)\n",
    "\n",
    "        return run_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceddaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (agent)",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
